# PostgreSQL MCP Server ä»£ç å®¡æŸ¥åé¦ˆå®æ–½è®¡åˆ’

**ç‰ˆæœ¬**: 1.0
**åˆ›å»ºæ—¥æœŸ**: 2026-01-15
**å…³è”æ–‡æ¡£**:
- [0012-pg-mcp-new-features-code-review.md](./0012-pg-mcp-new-features-code-review.md) - ä»£ç å®¡æŸ¥æŠ¥å‘Š

---

## 1. æ¦‚è¿°

æœ¬æ–‡æ¡£å®šä¹‰ä»£ç å®¡æŸ¥åé¦ˆçš„å®æ–½è®¡åˆ’ï¼ŒåŒ…æ‹¬ï¼š
- å®Œæˆå¾…å®ŒæˆåŠŸèƒ½
- åŠ å¼ºè¾¹ç¼˜åœºæ™¯æµ‹è¯•
- æå‡æµ‹è¯•è¦†ç›–ç‡

### 1.1 ä»»åŠ¡ä¾èµ–å›¾

```
E.1 QueryService é›†æˆ
 â”‚
 â”œâ”€â”€ E.2 /metrics HTTP ç«¯ç‚¹
 â”‚
 â””â”€â”€ E.3 enable_result_validation å®ç°
      â”‚
      â””â”€â”€ E.4 è¾¹ç¼˜åœºæ™¯æµ‹è¯•å¢å¼º
           â”‚
           â””â”€â”€ E.5 é›†æˆæµ‹è¯•å®Œå–„
```

### 1.2 å·¥ä½œé‡ä¼°ç®—

| ä»»åŠ¡ | ä¼˜å…ˆçº§ | å¤æ‚åº¦ |
|------|--------|--------|
| E.1 QueryService é›†æˆ | P0 | ä¸­ |
| E.2 /metrics HTTP ç«¯ç‚¹ | P1 | ä½ |
| E.3 enable_result_validation | P2 | ä¸­ |
| E.4 è¾¹ç¼˜åœºæ™¯æµ‹è¯• | P1 | ä¸­ |
| E.5 é›†æˆæµ‹è¯•å®Œå–„ | P1 | ä¸­ |

---

## 2. ä»»åŠ¡ E.1: QueryService é›†æˆ

**ç›®æ ‡**: å°† QueryExecutor å’Œ QueryExecutorManager é›†æˆåˆ° QueryService

**å‰ç½®æ¡ä»¶**: æ— 

### 2.1 ä¿®æ”¹ QueryService

**æ–‡ä»¶**: `src/pg_mcp/services/query_service.py`

```python
class QueryService:
    """Query service with integrated security and resilience."""

    def __init__(
        self,
        config: QueryServiceConfig,
        app_config: AppConfig,
        pool_manager: DatabasePoolManager,
        schema_cache: SchemaCache,
        openai_client: OpenAIClient,
        sql_parser: SQLParser,
        rate_limiter: RateLimiter | None = None,
        metrics_collector: MetricsCollector | None = None,  # æ–°å¢
        audit_logger: AuditLogger | None = None,  # æ–°å¢
    ):
        self._executor_manager = QueryExecutorManager()  # æ–°å¢
        self._metrics = metrics_collector
        self._audit_logger = audit_logger

        # ä¸ºæ¯ä¸ªæ•°æ®åº“æ³¨å†Œæ‰§è¡Œå™¨
        for db_config in app_config.databases:
            self._register_database_executor(db_config)

    def _register_database_executor(self, db_config: DatabaseConfig) -> None:
        """Register executor for a database."""
        access_policy = DatabaseAccessPolicy(db_config.access_policy)
        explain_validator = ExplainValidator(db_config.access_policy.explain_policy)

        self._executor_manager.register_database(
            name=db_config.name,
            pool=self._pool_manager.get_pool(db_config.name),
            sql_parser=self._sql_parser,
            access_policy=access_policy,
            explain_validator=explain_validator,
            audit_logger=self._audit_logger,
        )

    async def execute_query(self, request: QueryRequest) -> QueryResponse:
        """Execute query with full security and observability."""
        context = ExecutionContext(
            request_id=str(uuid.uuid4()),
            client_ip=request.client_ip,
            session_id=request.session_id,
        )

        # ä½¿ç”¨ metrics è¿½è¸ª
        if self._metrics:
            with self._metrics.track_request(request.database or "default"):
                return await self._execute_with_executor(request, context)
        else:
            return await self._execute_with_executor(request, context)

    async def _execute_with_executor(
        self,
        request: QueryRequest,
        context: ExecutionContext
    ) -> QueryResponse:
        """Execute using QueryExecutor."""
        # 1. è·å–æ‰§è¡Œå™¨
        executor = self._executor_manager.get_executor(request.database)

        # 2. ç”Ÿæˆ SQL
        sql = await self._generate_sql(request)

        # 3. é€šè¿‡æ‰§è¡Œå™¨æ‰§è¡Œï¼ˆåŒ…å«ç­–ç•¥æ£€æŸ¥ã€EXPLAINã€å®¡è®¡ï¼‰
        result = await executor.execute(
            sql=sql,
            limit=request.limit or self.config.max_result_rows,
            context=context,
            question=request.question,
        )

        return QueryResponse(
            success=True,
            sql=sql,
            result=result,
        )
```

### 2.2 æ›´æ–° Server åˆå§‹åŒ–

**æ–‡ä»¶**: `src/pg_mcp/server.py`

```python
from pg_mcp.observability.metrics import MetricsCollector
from pg_mcp.security.audit_logger import AuditLogger

class PgMcpServer:
    def __init__(self, config: AppConfig) -> None:
        # ... ç°æœ‰ä»£ç  ...

        # æ–°å¢ï¼šå¯è§‚æµ‹æ€§å’Œå®¡è®¡
        self._metrics_collector = MetricsCollector() if config.observability.metrics.enabled else None
        self._audit_logger = self._create_audit_logger(config.audit) if config.audit.enabled else None

        # æ›´æ–° QueryService åˆå§‹åŒ–
        self._query_service = QueryService(
            config=query_config,
            app_config=config,
            pool_manager=self._pool_manager,
            schema_cache=self._schema_cache,
            openai_client=self._openai_client,
            sql_parser=self._sql_parser,
            rate_limiter=self._rate_limiter,
            metrics_collector=self._metrics_collector,  # æ–°å¢
            audit_logger=self._audit_logger,  # æ–°å¢
        )

    def _create_audit_logger(self, config: AuditConfig) -> AuditLogger:
        """Create audit logger from config."""
        from pg_mcp.security.audit_logger import AuditStorage
        return AuditLogger(
            storage=AuditStorage(config.storage),
            file_path=config.file_path,
            max_size_mb=config.max_size_mb,
            max_files=config.max_files,
            redact_sql=config.redact_sql,
        )
```

### 2.3 å•å…ƒæµ‹è¯•

**æ–‡ä»¶**: `tests/unit/test_query_service_integration.py`

```python
class TestQueryServiceWithExecutor:
    """Tests for QueryService with QueryExecutor integration."""

    async def test_execute_with_policy_check(self): ...
    async def test_execute_with_explain_validation(self): ...
    async def test_execute_with_audit_logging(self): ...
    async def test_execute_with_metrics(self): ...
    async def test_execute_denied_table(self): ...
    async def test_execute_denied_column(self): ...
```

---

## 3. ä»»åŠ¡ E.2: /metrics HTTP ç«¯ç‚¹

**ç›®æ ‡**: æš´éœ² Prometheus æŒ‡æ ‡ç«¯ç‚¹

**å‰ç½®æ¡ä»¶**: E.1 å®Œæˆ

### 3.1 æ–¹æ¡ˆé€‰æ‹©

| æ–¹æ¡ˆ | ä¼˜ç‚¹ | ç¼ºç‚¹ |
|------|------|------|
| A. ç‹¬ç«‹ HTTP æœåŠ¡ | éš”ç¦»æ€§å¥½ | éœ€è¦é¢å¤–ç«¯å£ |
| B. FastMCP æ‰©å±• | æ— éœ€é¢å¤–ç«¯å£ | ä¾èµ–æ¡†æ¶æ”¯æŒ |
| C. ä½¿ç”¨ prometheus_client å†…ç½®æœåŠ¡ | ç®€å• | éœ€è¦é¢å¤–ç«¯å£ |

**æ¨è**: æ–¹æ¡ˆ C - ä½¿ç”¨ prometheus_client å†…ç½®æœåŠ¡

### 3.2 å®ç°

**æ–‡ä»¶**: `src/pg_mcp/observability/metrics_server.py`

```python
"""Prometheus metrics HTTP server."""

import threading
from prometheus_client import start_http_server, REGISTRY
import structlog

logger = structlog.get_logger()


class MetricsServer:
    """HTTP server for Prometheus metrics endpoint."""

    def __init__(self, port: int = 9090, path: str = "/metrics"):
        self.port = port
        self.path = path
        self._server_thread: threading.Thread | None = None

    def start(self) -> None:
        """Start the metrics server in a background thread."""
        def _run_server():
            start_http_server(self.port)
            logger.info("metrics_server_started", port=self.port)

        self._server_thread = threading.Thread(target=_run_server, daemon=True)
        self._server_thread.start()

    def stop(self) -> None:
        """Stop the metrics server."""
        # prometheus_client çš„ start_http_server ä¸æ”¯æŒä¼˜é›…å…³é—­
        # ç”±äºä½¿ç”¨ daemon=Trueï¼Œè¿›ç¨‹é€€å‡ºæ—¶ä¼šè‡ªåŠ¨æ¸…ç†
        logger.info("metrics_server_stopped")


def start_metrics_server(config: "MetricsConfig") -> MetricsServer | None:
    """Start metrics server if enabled."""
    if not config.enabled:
        return None

    server = MetricsServer(port=config.port, path=config.path)
    server.start()
    return server
```

### 3.3 é›†æˆåˆ° Server

**æ–‡ä»¶**: `src/pg_mcp/server.py` (ä¿®æ”¹)

```python
from pg_mcp.observability.metrics_server import start_metrics_server

class PgMcpServer:
    async def startup(self) -> None:
        # ... ç°æœ‰ä»£ç  ...

        # å¯åŠ¨ metrics æœåŠ¡å™¨
        if self.config.observability.metrics.enabled:
            self._metrics_server = start_metrics_server(self.config.observability.metrics)
            self._logger.info(
                "Metrics server started",
                port=self.config.observability.metrics.port
            )
```

---

## 4. ä»»åŠ¡ E.3: enable_result_validation å®ç°

**ç›®æ ‡**: å®ç° LLM ç»“æœéªŒè¯åŠŸèƒ½

**å‰ç½®æ¡ä»¶**: E.1 å®Œæˆ

### 4.1 åŠŸèƒ½è¯´æ˜

å½“æŸ¥è¯¢è¿”å›ç©ºç»“æœæ—¶ï¼Œä½¿ç”¨ LLM éªŒè¯æ˜¯å¦åˆç†ï¼š
- æ£€æŸ¥ SQL æ˜¯å¦æ­£ç¡®ç†è§£äº†ç”¨æˆ·æ„å›¾
- å¯¹äºé¢„æœŸåº”æœ‰æ•°æ®ä½†è¿”å›ç©ºçš„æƒ…å†µç»™å‡ºè­¦å‘Š

### 4.2 å®ç°

**æ–‡ä»¶**: `src/pg_mcp/services/result_validator.py`

```python
"""LLM-based query result validation."""

from dataclasses import dataclass
import structlog

from pg_mcp.infrastructure.openai_client import OpenAIClient


logger = structlog.get_logger()


@dataclass
class ValidationResult:
    """Result validation outcome."""
    is_valid: bool
    confidence: float  # 0.0 - 1.0
    explanation: str
    suggested_correction: str | None = None


class ResultValidator:
    """Validates query results using LLM."""

    VALIDATION_PROMPT = """
You are a SQL query result validator. Given:
- User's question: {question}
- Generated SQL: {sql}
- Result: {result_summary}

Determine if the result makes sense. If the result is empty, consider:
1. Is the query correctly understanding the user's intent?
2. Could there be a data issue (e.g., wrong table, wrong filter)?
3. Is empty result actually expected?

Respond in JSON format:
{{
    "is_valid": true/false,
    "confidence": 0.0-1.0,
    "explanation": "brief explanation",
    "suggested_correction": "SQL correction if needed, or null"
}}
"""

    def __init__(self, openai_client: OpenAIClient):
        self._client = openai_client

    async def validate(
        self,
        question: str,
        sql: str,
        row_count: int,
        sample_data: list[dict] | None = None,
    ) -> ValidationResult:
        """Validate query result."""
        # åªå¯¹ç©ºç»“æœæˆ–å¯ç–‘ç»“æœè¿›è¡ŒéªŒè¯
        if row_count > 0 and row_count < 1000:
            return ValidationResult(
                is_valid=True,
                confidence=1.0,
                explanation="Result count is within expected range",
            )

        result_summary = self._summarize_result(row_count, sample_data)

        prompt = self.VALIDATION_PROMPT.format(
            question=question,
            sql=sql,
            result_summary=result_summary,
        )

        try:
            response = await self._client.generate_validation(prompt)
            return self._parse_response(response)
        except Exception as e:
            logger.warning("result_validation_failed", error=str(e))
            return ValidationResult(
                is_valid=True,
                confidence=0.5,
                explanation=f"Validation skipped: {e}",
            )

    def _summarize_result(
        self,
        row_count: int,
        sample_data: list[dict] | None
    ) -> str:
        """Create a summary of the result for LLM."""
        if row_count == 0:
            return "Empty result (0 rows)"

        summary = f"{row_count} rows returned"
        if sample_data:
            summary += f"\nSample columns: {list(sample_data[0].keys())}"

        return summary

    def _parse_response(self, response: str) -> ValidationResult:
        """Parse LLM response into ValidationResult."""
        import json
        try:
            data = json.loads(response)
            return ValidationResult(
                is_valid=data.get("is_valid", True),
                confidence=data.get("confidence", 0.5),
                explanation=data.get("explanation", ""),
                suggested_correction=data.get("suggested_correction"),
            )
        except json.JSONDecodeError:
            return ValidationResult(
                is_valid=True,
                confidence=0.5,
                explanation="Failed to parse validation response",
            )
```

### 4.3 é›†æˆåˆ° QueryService

```python
# åœ¨ QueryService._execute_with_executor ä¸­æ·»åŠ 
if self.config.enable_result_validation and result.row_count == 0:
    validation = await self._result_validator.validate(
        question=request.question,
        sql=sql,
        row_count=result.row_count,
    )
    if not validation.is_valid:
        logger.warning(
            "result_validation_warning",
            confidence=validation.confidence,
            explanation=validation.explanation,
        )
        # å¯é€‰ï¼šè¿”å›è­¦å‘Šç»™ç”¨æˆ·
```

---

## 5. ä»»åŠ¡ E.4: è¾¹ç¼˜åœºæ™¯æµ‹è¯•å¢å¼º

**ç›®æ ‡**: å¢åŠ è¾¹ç¼˜åœºæ™¯æµ‹è¯•è¦†ç›–

**å‰ç½®æ¡ä»¶**: E.1 å®Œæˆ

### 5.1 SQL Parser è¾¹ç¼˜åœºæ™¯

**æ–‡ä»¶**: `tests/unit/test_sql_parser_edge_cases.py`

```python
"""Edge case tests for SQL parser."""

import pytest
from pg_mcp.infrastructure.sql_parser import SQLParser


class TestSQLParserEdgeCases:
    """Edge case tests for SQL parser."""

    @pytest.fixture
    def parser(self) -> SQLParser:
        return SQLParser()

    # === ç©ºå€¼å’Œç‰¹æ®Šå­—ç¬¦ ===

    def test_empty_string(self, parser: SQLParser) -> None:
        """Test empty SQL string."""
        result = parser.parse("")
        assert result.error_message is not None

    def test_whitespace_only(self, parser: SQLParser) -> None:
        """Test whitespace-only SQL."""
        result = parser.parse("   \n\t  ")
        assert result.error_message is not None

    def test_unicode_characters(self, parser: SQLParser) -> None:
        """Test SQL with unicode characters."""
        result = parser.parse("SELECT * FROM users WHERE name = 'ä¸­æ–‡'")
        assert result.is_readonly is True

    def test_emoji_in_string(self, parser: SQLParser) -> None:
        """Test SQL with emoji in string literal."""
        result = parser.parse("SELECT * FROM posts WHERE content LIKE '%ğŸ˜€%'")
        assert result.is_readonly is True

    def test_null_byte(self, parser: SQLParser) -> None:
        """Test SQL with null byte."""
        result = parser.parse("SELECT * FROM users WHERE name = 'test\x00'")
        # Should either parse successfully or fail gracefully
        assert result.error_message is not None or result.is_readonly is True

    # === æé•¿è¾“å…¥ ===

    def test_very_long_query(self, parser: SQLParser) -> None:
        """Test very long SQL query."""
        columns = ", ".join([f"col{i}" for i in range(1000)])
        sql = f"SELECT {columns} FROM large_table"
        result = parser.parse(sql)
        assert result.is_readonly is True

    def test_deeply_nested_subquery(self, parser: SQLParser) -> None:
        """Test deeply nested subqueries."""
        sql = "SELECT * FROM t1"
        for i in range(20):
            sql = f"SELECT * FROM ({sql}) AS sub{i}"
        result = parser.parse(sql)
        assert result.is_readonly is True

    def test_many_joins(self, parser: SQLParser) -> None:
        """Test query with many JOINs."""
        sql = "SELECT * FROM t1"
        for i in range(50):
            sql += f" JOIN t{i+2} ON t{i+1}.id = t{i+2}.id"
        result = parser.parse(sql)
        assert result.is_readonly is True

    # === å¤æ‚ CTE ===

    def test_recursive_cte(self, parser: SQLParser) -> None:
        """Test recursive CTE."""
        sql = """
        WITH RECURSIVE cte AS (
            SELECT 1 AS n
            UNION ALL
            SELECT n + 1 FROM cte WHERE n < 10
        )
        SELECT * FROM cte
        """
        result = parser.parse(sql)
        assert result.is_readonly is True

    def test_multiple_ctes(self, parser: SQLParser) -> None:
        """Test multiple CTEs."""
        sql = """
        WITH
            cte1 AS (SELECT 1 AS a),
            cte2 AS (SELECT 2 AS b),
            cte3 AS (SELECT * FROM cte1, cte2)
        SELECT * FROM cte3
        """
        result = parser.parse(sql)
        assert result.is_readonly is True

    # === çª—å£å‡½æ•° ===

    def test_window_functions(self, parser: SQLParser) -> None:
        """Test window functions."""
        sql = """
        SELECT
            id,
            ROW_NUMBER() OVER (ORDER BY id) AS rn,
            LAG(value) OVER (PARTITION BY category ORDER BY id) AS prev_value,
            SUM(value) OVER (ORDER BY id ROWS BETWEEN UNBOUNDED PRECEDING AND CURRENT ROW) AS running_total
        FROM data
        """
        result = parser.parse(sql)
        assert result.is_readonly is True

    # === JSON æ“ä½œ ===

    def test_json_operators(self, parser: SQLParser) -> None:
        """Test PostgreSQL JSON operators."""
        sql = """
        SELECT
            data->>'name' AS name,
            data->'address'->>'city' AS city,
            data #>> '{nested,deep,value}' AS deep_value
        FROM json_table
        WHERE data @> '{"active": true}'
        """
        result = parser.parse(sql)
        assert result.is_readonly is True

    # === æ•°ç»„æ“ä½œ ===

    def test_array_operations(self, parser: SQLParser) -> None:
        """Test PostgreSQL array operations."""
        sql = """
        SELECT *
        FROM items
        WHERE tags && ARRAY['tag1', 'tag2']
        AND categories @> ARRAY['cat1']
        """
        result = parser.parse(sql)
        assert result.is_readonly is True

    # === ç‰¹æ®Šè¡¨å ===

    def test_reserved_word_table_name(self, parser: SQLParser) -> None:
        """Test table name that is a reserved word."""
        result = parser.parse('SELECT * FROM "order"')
        assert result.is_readonly is True

    def test_schema_qualified_name(self, parser: SQLParser) -> None:
        """Test schema-qualified table name."""
        result = parser.parse("SELECT * FROM public.users")
        assert result.is_readonly is True
        assert "public" in result.schemas

    def test_catalog_schema_table(self, parser: SQLParser) -> None:
        """Test catalog.schema.table format."""
        result = parser.parse("SELECT * FROM mydb.public.users")
        assert result.is_readonly is True
```

### 5.2 Access Policy è¾¹ç¼˜åœºæ™¯

**æ–‡ä»¶**: `tests/unit/security/test_access_policy_edge_cases.py`

```python
"""Edge case tests for access policy."""

import pytest
from pg_mcp.config.models import (
    AccessPolicyConfig,
    TableAccessConfig,
    ColumnAccessConfig,
)
from pg_mcp.security.access_policy import DatabaseAccessPolicy
from pg_mcp.infrastructure.sql_parser import SQLParser, ParsedSQLInfo


class TestAccessPolicyEdgeCases:
    """Edge case tests for access policy."""

    @pytest.fixture
    def parser(self) -> SQLParser:
        return SQLParser()

    # === ç©ºé…ç½® ===

    def test_empty_config_allows_all(self, parser: SQLParser) -> None:
        """Test that empty config allows all access."""
        config = AccessPolicyConfig()
        policy = DatabaseAccessPolicy(config)

        parsed = parser.parse("SELECT * FROM any_table")
        result = policy.validate_sql(parsed)
        assert result.passed is True

    # === é€šé…ç¬¦æ¨¡å¼ ===

    def test_wildcard_column_pattern(self, parser: SQLParser) -> None:
        """Test wildcard column patterns."""
        config = AccessPolicyConfig(
            columns=ColumnAccessConfig(
                denied_patterns=["*.*password*", "*.*secret*", "*.*token*"],
            ),
        )
        policy = DatabaseAccessPolicy(config)

        # Should block any password column
        parsed = ParsedSQLInfo(
            sql="SELECT user_password FROM users",
            schemas=["public"],
            tables=["users"],
            columns=[("users", "user_password")],
            has_select_star=False,
            select_star_tables=[],
            is_readonly=True,
        )
        result = policy.validate_sql(parsed)
        assert result.passed is False

    # === å¤§å°å†™æ··åˆ ===

    def test_mixed_case_table_names(self, parser: SQLParser) -> None:
        """Test mixed case table names."""
        config = AccessPolicyConfig(
            tables=TableAccessConfig(denied=["users"]),
        )
        policy = DatabaseAccessPolicy(config)

        # Should block regardless of case
        for table_name in ["USERS", "Users", "uSeRs"]:
            parsed = ParsedSQLInfo(
                sql=f"SELECT * FROM {table_name}",
                schemas=["public"],
                tables=[table_name.lower()],  # Parser normalizes to lowercase
                columns=[],
                has_select_star=True,
                select_star_tables=[table_name.lower()],
                is_readonly=True,
            )
            result = policy.validate_sql(parsed)
            assert result.passed is False, f"Should block {table_name}"

    # === å¤šè¡¨ JOIN åœºæ™¯ ===

    def test_join_with_one_denied_table(self, parser: SQLParser) -> None:
        """Test JOIN where one table is denied."""
        config = AccessPolicyConfig(
            tables=TableAccessConfig(denied=["secrets"]),
        )
        policy = DatabaseAccessPolicy(config)

        parsed = parser.parse("""
            SELECT u.name, s.data
            FROM users u
            JOIN secrets s ON u.id = s.user_id
        """)
        result = policy.validate_sql(parsed)
        assert result.passed is False

    # === å­æŸ¥è¯¢åœºæ™¯ ===

    def test_subquery_in_where(self, parser: SQLParser) -> None:
        """Test subquery in WHERE clause."""
        config = AccessPolicyConfig(
            tables=TableAccessConfig(denied=["admin_users"]),
        )
        policy = DatabaseAccessPolicy(config)

        parsed = parser.parse("""
            SELECT * FROM users
            WHERE id IN (SELECT user_id FROM admin_users)
        """)
        result = policy.validate_sql(parsed)
        assert result.passed is False

    def test_subquery_in_from(self, parser: SQLParser) -> None:
        """Test subquery in FROM clause."""
        config = AccessPolicyConfig(
            tables=TableAccessConfig(denied=["secrets"]),
        )
        policy = DatabaseAccessPolicy(config)

        parsed = parser.parse("""
            SELECT * FROM (SELECT * FROM secrets) AS sub
        """)
        result = policy.validate_sql(parsed)
        assert result.passed is False

    # === UNION åœºæ™¯ ===

    def test_union_with_denied_table(self, parser: SQLParser) -> None:
        """Test UNION with one denied table."""
        config = AccessPolicyConfig(
            tables=TableAccessConfig(denied=["secrets"]),
        )
        policy = DatabaseAccessPolicy(config)

        parsed = parser.parse("""
            SELECT name FROM users
            UNION
            SELECT data FROM secrets
        """)
        result = policy.validate_sql(parsed)
        assert result.passed is False

    # === åˆ«ååœºæ™¯ ===

    def test_column_alias_does_not_bypass(self, parser: SQLParser) -> None:
        """Test that column alias doesn't bypass restrictions."""
        config = AccessPolicyConfig(
            columns=ColumnAccessConfig(denied=["users.password"]),
        )
        policy = DatabaseAccessPolicy(config)

        parsed = parser.parse("SELECT password AS pwd FROM users")
        result = policy.validate_sql(parsed)
        assert result.passed is False

    # === å‡½æ•°åŒ…è£…åœºæ™¯ ===

    def test_function_wrapped_column(self, parser: SQLParser) -> None:
        """Test that function-wrapped columns are still checked."""
        config = AccessPolicyConfig(
            columns=ColumnAccessConfig(denied=["users.password"]),
        )
        policy = DatabaseAccessPolicy(config)

        # å‡½æ•°åŒ…è£…çš„åˆ—ä¹Ÿåº”è¯¥è¢«æ£€æŸ¥
        parsed = parser.parse("SELECT UPPER(password) FROM users")
        result = policy.validate_sql(parsed)
        # æ³¨æ„ï¼šè¿™å–å†³äº SQL parser æ˜¯å¦èƒ½è§£æå‡½æ•°å‚æ•°ä¸­çš„åˆ—
        # å¦‚æœ parser ä¸æ”¯æŒï¼Œè¿™ä¸ªæµ‹è¯•å¯èƒ½éœ€è¦è°ƒæ•´

    # === å†²çªé…ç½® ===

    def test_allowed_overrides_denied(self, parser: SQLParser) -> None:
        """Test that allowed list overrides denied list."""
        config = AccessPolicyConfig(
            tables=TableAccessConfig(
                allowed=["users"],
                denied=["users"],  # åŒæ—¶å‡ºç°åœ¨ä¸¤ä¸ªåˆ—è¡¨ä¸­
            ),
        )
        # åº”è¯¥åœ¨é…ç½®éªŒè¯æ—¶æŠ¥é”™
        with pytest.raises(ValueError):
            config.validate_consistency()
```

### 5.3 Rate Limiter è¾¹ç¼˜åœºæ™¯

**æ–‡ä»¶**: `tests/unit/resilience/test_rate_limiter_edge_cases.py`

```python
"""Edge case tests for rate limiter."""

import pytest
import asyncio
import time
from pg_mcp.resilience.rate_limiter import RateLimiter, RateLimitConfig


class TestRateLimiterEdgeCases:
    """Edge case tests for rate limiter."""

    # === å¹¶å‘åœºæ™¯ ===

    async def test_concurrent_requests(self) -> None:
        """Test concurrent request handling."""
        config = RateLimitConfig(
            requests_per_minute=10,
            requests_per_hour=100,
        )
        limiter = RateLimiter(config)

        # å¹¶å‘å‘é€ 20 ä¸ªè¯·æ±‚
        async def make_request(i: int) -> bool:
            result = limiter.check_request(client_ip=f"192.168.1.{i % 10}")
            return result.allowed

        results = await asyncio.gather(*[make_request(i) for i in range(20)])

        # åº”è¯¥æœ‰ 10 ä¸ªæˆåŠŸï¼Œ10 ä¸ªè¢«é™åˆ¶
        assert sum(results) == 10

    # === æ—¶é—´è¾¹ç•Œ ===

    def test_window_boundary_reset(self) -> None:
        """Test rate limit reset at window boundary."""
        config = RateLimitConfig(requests_per_minute=5)
        limiter = RateLimiter(config)

        # ç”¨å®Œé…é¢
        for _ in range(5):
            result = limiter.check_request()
            assert result.allowed is True

        # ç¬¬ 6 ä¸ªåº”è¯¥è¢«æ‹’ç»
        result = limiter.check_request()
        assert result.allowed is False

        # é‡ç½®ååº”è¯¥å¯ä»¥ç»§ç»­
        limiter.reset()
        result = limiter.check_request()
        assert result.allowed is True

    # === Token æ¶ˆè€—åœºæ™¯ ===

    def test_token_limit_exact_boundary(self) -> None:
        """Test token limit at exact boundary."""
        config = RateLimitConfig(
            requests_per_minute=100,
            openai_tokens_per_minute=1000,
        )
        limiter = RateLimiter(config)

        # æ¶ˆè€—æ°å¥½ 1000 tokens
        limiter.record_tokens(1000)

        # ä¸‹ä¸€ä¸ªè¯·æ±‚åº”è¯¥è¢«å…è®¸ï¼ˆåˆšå¥½åˆ°è¾¹ç•Œï¼‰
        result = limiter.check_request()
        assert result.allowed is True

        # å†æ¶ˆè€— 1 ä¸ª token åº”è¯¥å¯¼è‡´åç»­è¢«é™åˆ¶
        limiter.record_tokens(1)
        # æ£€æŸ¥ token é™åˆ¶çŠ¶æ€
        status = limiter.get_status()
        assert status["token_count"] > config.openai_tokens_per_minute

    # === å®¢æˆ·ç«¯éš”ç¦» ===

    def test_client_isolation(self) -> None:
        """Test that different clients are isolated."""
        config = RateLimitConfig(
            requests_per_minute=100,
            client_requests_per_minute=5,
        )
        limiter = RateLimiter(config)

        # Client A ç”¨å®Œé…é¢
        for _ in range(5):
            result = limiter.check_request(client_ip="192.168.1.1")
            assert result.allowed is True

        result = limiter.check_request(client_ip="192.168.1.1")
        assert result.allowed is False

        # Client B åº”è¯¥ä¸å—å½±å“
        result = limiter.check_request(client_ip="192.168.1.2")
        assert result.allowed is True

    # === è¿‡æœŸæ¸…ç† ===

    def test_stale_bucket_cleanup(self) -> None:
        """Test cleanup of stale client buckets."""
        config = RateLimitConfig(
            client_requests_per_minute=5,
            bucket_expiry_seconds=1,  # 1 ç§’è¿‡æœŸ
        )
        limiter = RateLimiter(config)

        # ä¸ºå¤šä¸ªå®¢æˆ·ç«¯åˆ›å»º bucket
        for i in range(100):
            limiter.check_request(client_ip=f"192.168.1.{i}")

        # ç­‰å¾…è¿‡æœŸ
        time.sleep(1.5)

        # æ¸…ç†
        limiter.cleanup_stale_buckets()

        # éªŒè¯ bucket å·²è¢«æ¸…ç†
        status = limiter.get_status()
        assert status.get("active_clients", 0) == 0
```

### 5.4 Retry Executor è¾¹ç¼˜åœºæ™¯

**æ–‡ä»¶**: `tests/unit/resilience/test_retry_executor_edge_cases.py`

```python
"""Edge case tests for retry executor."""

import pytest
from unittest.mock import AsyncMock, MagicMock
from pg_mcp.resilience.retry_executor import (
    RetryExecutor,
    RetryConfig,
    OpenAIRetryExecutor,
    DatabaseRetryExecutor,
)
from pg_mcp.resilience.backoff import BackoffStrategyType


class TestRetryExecutorEdgeCases:
    """Edge case tests for retry executor."""

    # === é›¶é‡è¯• ===

    async def test_zero_retries(self) -> None:
        """Test with zero max retries."""
        config = RetryConfig(max_retries=0)
        executor = RetryExecutor(config)

        operation = AsyncMock(side_effect=ValueError("error"))

        with pytest.raises(ValueError):
            await executor.execute_with_retry(operation)

        # åº”è¯¥åªè°ƒç”¨ä¸€æ¬¡
        assert operation.call_count == 1

    # === ç«‹å³æˆåŠŸ ===

    async def test_immediate_success(self) -> None:
        """Test operation that succeeds immediately."""
        config = RetryConfig(max_retries=3)
        executor = RetryExecutor(config)

        operation = AsyncMock(return_value="success")

        result = await executor.execute_with_retry(operation)

        assert result == "success"
        assert operation.call_count == 1

    # === æœ€åä¸€æ¬¡é‡è¯•æˆåŠŸ ===

    async def test_success_on_last_retry(self) -> None:
        """Test success on the last retry attempt."""
        config = RetryConfig(max_retries=3)
        executor = RetryExecutor(config)

        call_count = 0

        async def flaky_operation():
            nonlocal call_count
            call_count += 1
            if call_count < 4:  # å‰ 3 æ¬¡å¤±è´¥
                raise ConnectionError("transient error")
            return "success"

        result = await executor.execute_with_retry(flaky_operation)

        assert result == "success"
        assert call_count == 4  # 1 åˆå§‹ + 3 é‡è¯•

    # === ä¸å¯é‡è¯•é”™è¯¯ ===

    async def test_non_retryable_error_immediate_fail(self) -> None:
        """Test that non-retryable errors fail immediately."""
        config = RetryConfig(
            max_retries=3,
            retryable_errors=[ConnectionError],
        )
        executor = RetryExecutor(config)

        operation = AsyncMock(side_effect=ValueError("not retryable"))

        with pytest.raises(ValueError):
            await executor.execute_with_retry(operation)

        # ä¸å¯é‡è¯•çš„é”™è¯¯åº”è¯¥ç«‹å³å¤±è´¥
        assert operation.call_count == 1

    # === æ··åˆé”™è¯¯ ===

    async def test_mixed_errors(self) -> None:
        """Test handling of mixed retryable and non-retryable errors."""
        config = RetryConfig(
            max_retries=3,
            retryable_errors=[ConnectionError],
        )
        executor = RetryExecutor(config)

        call_count = 0

        async def operation():
            nonlocal call_count
            call_count += 1
            if call_count == 1:
                raise ConnectionError("retryable")
            raise ValueError("not retryable")

        with pytest.raises(ValueError):
            await executor.execute_with_retry(operation)

        # ç¬¬ä¸€æ¬¡ ConnectionError åé‡è¯•ï¼Œç¬¬äºŒæ¬¡ ValueError ç«‹å³å¤±è´¥
        assert call_count == 2

    # === OpenAI ç‰¹å®šé”™è¯¯ ===

    async def test_openai_rate_limit_is_retryable(self) -> None:
        """Test that OpenAI RateLimitError is retryable."""
        executor = OpenAIRetryExecutor()

        # æ¨¡æ‹Ÿ RateLimitError
        class RateLimitError(Exception):
            pass

        call_count = 0

        async def operation():
            nonlocal call_count
            call_count += 1
            if call_count < 3:
                raise RateLimitError("rate limited")
            return "success"

        # éœ€è¦ mock _is_default_retryable æ–¹æ³•
        result = await executor.execute_with_retry(operation)
        assert call_count >= 1

    # === è¶…æ—¶åœºæ™¯ ===

    async def test_operation_timeout(self) -> None:
        """Test operation that times out."""
        import asyncio

        config = RetryConfig(max_retries=2)
        executor = RetryExecutor(config)

        async def slow_operation():
            await asyncio.sleep(10)
            return "success"

        with pytest.raises(asyncio.TimeoutError):
            await asyncio.wait_for(
                executor.execute_with_retry(slow_operation),
                timeout=0.1
            )
```

---

## 6. ä»»åŠ¡ E.5: é›†æˆæµ‹è¯•å®Œå–„

**ç›®æ ‡**: ä½¿ç”¨ testcontainers å®Œå–„é›†æˆæµ‹è¯•

**å‰ç½®æ¡ä»¶**: E.4 å®Œæˆ

### 6.1 Testcontainers è®¾ç½®

**æ–‡ä»¶**: `tests/integration/conftest.py`

```python
"""Integration test fixtures with testcontainers."""

import pytest
import pytest_asyncio
from testcontainers.postgres import PostgresContainer


@pytest.fixture(scope="session")
def postgres_container():
    """Create a PostgreSQL container for integration tests."""
    with PostgresContainer(
        image="postgres:16",
        username="test",
        password="test",
        dbname="testdb",
    ) as postgres:
        yield postgres


@pytest_asyncio.fixture
async def db_pool(postgres_container):
    """Create a database pool connected to the test container."""
    import asyncpg

    pool = await asyncpg.create_pool(
        host=postgres_container.get_container_host_ip(),
        port=postgres_container.get_exposed_port(5432),
        user="test",
        password="test",
        database="testdb",
        min_size=1,
        max_size=5,
    )

    # åˆ›å»ºæµ‹è¯•è¡¨
    async with pool.acquire() as conn:
        await conn.execute("""
            CREATE TABLE IF NOT EXISTS users (
                id SERIAL PRIMARY KEY,
                name VARCHAR(100),
                email VARCHAR(100),
                password VARCHAR(100),
                created_at TIMESTAMP DEFAULT NOW()
            )
        """)
        await conn.execute("""
            CREATE TABLE IF NOT EXISTS orders (
                id SERIAL PRIMARY KEY,
                user_id INT REFERENCES users(id),
                total DECIMAL(10,2),
                status VARCHAR(20)
            )
        """)
        # æ’å…¥æµ‹è¯•æ•°æ®
        await conn.execute("""
            INSERT INTO users (name, email, password) VALUES
            ('Alice', 'alice@example.com', 'secret1'),
            ('Bob', 'bob@example.com', 'secret2')
        """)

    yield pool

    await pool.close()
```

### 6.2 å®Œæ•´æµç¨‹é›†æˆæµ‹è¯•

**æ–‡ä»¶**: `tests/integration/test_full_flow.py`

```python
"""Full flow integration tests."""

import pytest
import pytest_asyncio
from pg_mcp.config.models import (
    AppConfig,
    DatabaseConfig,
    OpenAISettings,
    AccessPolicyConfig,
    TableAccessConfig,
    ColumnAccessConfig,
)
from pg_mcp.services.query_executor import QueryExecutor, ExecutionContext
from pg_mcp.security.access_policy import DatabaseAccessPolicy
from pg_mcp.security.explain_validator import ExplainValidator
from pg_mcp.infrastructure.sql_parser import SQLParser


class TestFullFlow:
    """Full flow integration tests."""

    @pytest_asyncio.fixture
    async def executor(self, db_pool):
        """Create a QueryExecutor with real database."""
        config = AccessPolicyConfig(
            allowed_schemas=["public"],
            tables=TableAccessConfig(allowed=["users", "orders"]),
            columns=ColumnAccessConfig(denied=["users.password"]),
        )

        return QueryExecutor(
            pool=db_pool,
            sql_parser=SQLParser(),
            access_policy=DatabaseAccessPolicy(config),
            explain_validator=ExplainValidator(config.explain_policy),
            audit_logger=None,
        )

    async def test_query_success(self, executor) -> None:
        """Test successful query execution."""
        context = ExecutionContext(
            request_id="test-1",
            client_ip="127.0.0.1",
        )

        result = await executor.execute(
            sql="SELECT id, name, email FROM users",
            limit=100,
            context=context,
            question="List all users",
        )

        assert result.row_count == 2
        assert "Alice" in str(result.rows)

    async def test_query_with_password_denied(self, executor) -> None:
        """Test that password column is denied."""
        from pg_mcp.security.access_policy import ColumnAccessDeniedError

        context = ExecutionContext(request_id="test-2")

        with pytest.raises(ColumnAccessDeniedError):
            await executor.execute(
                sql="SELECT id, name, password FROM users",
                limit=100,
                context=context,
            )

    async def test_query_with_denied_table(self, executor) -> None:
        """Test that non-allowed table is denied."""
        from pg_mcp.security.access_policy import TableAccessDeniedError

        context = ExecutionContext(request_id="test-3")

        with pytest.raises(TableAccessDeniedError):
            await executor.execute(
                sql="SELECT * FROM admin_users",
                limit=100,
                context=context,
            )

    async def test_query_with_rate_limit(self, db_pool) -> None:
        """Test query with rate limiting."""
        from pg_mcp.resilience.rate_limiter import RateLimiter, RateLimitConfig

        config = RateLimitConfig(requests_per_minute=2)
        limiter = RateLimiter(config)

        # å‰ä¸¤ä¸ªè¯·æ±‚åº”è¯¥æˆåŠŸ
        assert limiter.check_request().allowed is True
        assert limiter.check_request().allowed is True

        # ç¬¬ä¸‰ä¸ªåº”è¯¥è¢«é™åˆ¶
        assert limiter.check_request().allowed is False
```

---

## 7. éªŒæ”¶æ ‡å‡†

### 7.1 åŠŸèƒ½éªŒæ”¶

| ä»»åŠ¡ | éªŒæ”¶æ ‡å‡† |
|------|----------|
| E.1 | QueryService æ­£ç¡®ä½¿ç”¨ QueryExecutorManager |
| E.1 | ç­–ç•¥æ£€æŸ¥ã€EXPLAIN éªŒè¯ã€å®¡è®¡æ—¥å¿—æ­£å¸¸å·¥ä½œ |
| E.2 | `/metrics` ç«¯ç‚¹è¿”å› Prometheus æ ¼å¼æŒ‡æ ‡ |
| E.3 | ç©ºç»“æœæ—¶ LLM éªŒè¯æ­£å¸¸å·¥ä½œ |
| E.4 | æ‰€æœ‰è¾¹ç¼˜åœºæ™¯æµ‹è¯•é€šè¿‡ |
| E.5 | é›†æˆæµ‹è¯•åœ¨ testcontainers ä¸­é€šè¿‡ |

### 7.2 æµ‹è¯•è¦†ç›–ç›®æ ‡

| æ¨¡å— | å½“å‰è¦†ç›–ç‡ | ç›®æ ‡è¦†ç›–ç‡ |
|------|-----------|-----------|
| services/query_executor.py | 28% | >= 85% |
| observability/tracing.py | 84% | >= 85% |
| infrastructure/sql_parser.py | 93% | >= 95% |
| **æ€»ä½“** | 85% | >= 90% |

---

## 8. æ‰§è¡Œè®¡åˆ’

### 8.1 ä»»åŠ¡ä¼˜å…ˆçº§

```
ç¬¬ä¸€é˜¶æ®µï¼ˆP0ï¼‰:
â”œâ”€â”€ E.1 QueryService é›†æˆ
â””â”€â”€ E.4 è¾¹ç¼˜åœºæ™¯æµ‹è¯•

ç¬¬äºŒé˜¶æ®µï¼ˆP1ï¼‰:
â”œâ”€â”€ E.2 /metrics HTTP ç«¯ç‚¹
â””â”€â”€ E.5 é›†æˆæµ‹è¯•å®Œå–„

ç¬¬ä¸‰é˜¶æ®µï¼ˆP2ï¼‰:
â””â”€â”€ E.3 enable_result_validation
```

### 8.2 æ£€æŸ¥æ¸…å•

- [ ] E.1 QueryService é›†æˆå®Œæˆ
- [ ] E.2 /metrics ç«¯ç‚¹å¯è®¿é—®
- [ ] E.3 ç»“æœéªŒè¯åŠŸèƒ½å®ç°
- [ ] E.4 è¾¹ç¼˜åœºæ™¯æµ‹è¯• > 50 ä¸ªç”¨ä¾‹
- [ ] E.5 é›†æˆæµ‹è¯•ä½¿ç”¨ testcontainers
- [ ] æ€»ä½“æµ‹è¯•è¦†ç›–ç‡ >= 90%

---

## ä¿®è®¢å†å²

| ç‰ˆæœ¬ | æ—¥æœŸ | ä¿®æ”¹å†…å®¹ | ä½œè€… |
|------|------|---------|------|
| 1.0 | 2026-01-15 | åˆå§‹ç‰ˆæœ¬ | Claude Code |
